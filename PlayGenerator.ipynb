{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO93KzZu7SpsvWlE3BaKFhu"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KiiOI9mN9lZk"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import sequence\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLr4nmm7EE01",
        "outputId": "9377c63f-8ffd-4545-ce4f-2f426d4c72aa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "reading content of file"
      ],
      "metadata": {
        "id": "rmuqE8AW_yeP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=open(path_to_file,'rb').read().decode(encoding='utf-8')\n",
        "print('length of text :{} characters'.format(len(text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKodLcBF_wQI",
        "outputId": "fa9abb80-76d8-4642-c52c-3fcb4e326e79"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of text :1115394 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#encoding\n",
        "vocab=sorted(set(text))\n",
        "#creating a mapping  from unique characters to indices\n",
        "char2indx={u:i for i,u in enumerate(vocab)}\n",
        "indx2char=np.array(vocab)\n",
        "def text_to_int(text):\n",
        "  return np.array([char2indx[c] for c in text])\n",
        "text_as_int=text_to_int(text)"
      ],
      "metadata": {
        "id": "ELO9xqGNAgNq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lets look part of our encoded text\n",
        "print(\"text: \",text[:13])\n",
        "print(\"encoded: \",text_to_int(text[:13]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzTIJsvICxSN",
        "outputId": "d5ea49cc-0e67-4408-eb78-8d68ee235aaf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text:  First Citizen\n",
            "encoded:  [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#converting integer to text\n",
        "def int_to_text(ints):\n",
        "  try:\n",
        "    ints=ints.numpy()\n",
        "  except:\n",
        "    pass\n",
        "  return ''.join(indx2char[ints])\n",
        "print(int_to_text(text_as_int[:13]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Dv3Cd-PDRfM",
        "outputId": "65ea5904-50ed-4f97-bd21-5c2c3bde4fbb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating training example"
      ],
      "metadata": {
        "id": "2Kb5FW26EQTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length=100 #length of sequence for training example\n",
        "example_per_epoch=len(text)//(seq_length+1)\n",
        "#creating training examples/targets\n",
        "char_datasets=tf.data.Dataset.from_tensor_slices(text_as_int)"
      ],
      "metadata": {
        "id": "GRXfIAPvD9Bs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences=char_datasets.batch(seq_length+1, drop_remainder=True)"
      ],
      "metadata": {
        "id": "JBkQnF9_FbHZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting seqlen 101  into inout and output\n",
        "def split_input_target(chunk):\n",
        "  input_text=chunk[:-1]#hell\n",
        "  target_text=chunk[1:]#ello\n",
        "  return input_text,target_text #hell, ello\n",
        "dataset=sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "JZdv40QeFwAX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in dataset.take(2):\n",
        "  print(\"\\n\\nExample\\n\")\n",
        "  print(\"INPUT\")\n",
        "  print(int_to_text(x))\n",
        "  print(\"\\nOUTPUT\\n\")\n",
        "  print(int_to_text(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDRpUcpqGhCF",
        "outputId": "f44b2e37-8234-4480-d496-02439bb7117d",
        "collapsed": true
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Example\n",
            "\n",
            "INPUT\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n",
            "\n",
            "OUTPUT\n",
            "\n",
            "irst Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You \n",
            "\n",
            "\n",
            "Example\n",
            "\n",
            "INPUT\n",
            "are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you \n",
            "\n",
            "OUTPUT\n",
            "\n",
            "re all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#making training data\n",
        "BATCH_SIZE=64\n",
        "VOCAB_SIZE=len(vocab)\n",
        "EMBEDDING_DIM=256\n",
        "RNN_UNITS=1024\n",
        "#BUFFER SIZE TO SUFFLE THE DATASET\n",
        "BUFFER_SIZE=10000\n",
        "data=dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE,drop_remainder=True)"
      ],
      "metadata": {
        "id": "-xTHe6SoJuZr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "building model"
      ],
      "metadata": {
        "id": "31oKIThsKpde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Embedding(vocab_size, embedding_dim),\n",
        "        keras.layers.LSTM(rnn_units,\n",
        "                          return_sequences=True,\n",
        "                          stateful=True,\n",
        "                          recurrent_initializer='glorot_uniform'),\n",
        "        keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "# Build the model\n",
        "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
        "\n",
        "# Specify input shape manually\n",
        "model.build(input_shape=(BATCH_SIZE, None))\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "xPbMjs7vKm4J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "7fecee00-e9c7-4941-b0d4-c32105263983"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │          \u001b[38;5;34m16,640\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)            │       \u001b[38;5;34m5,246,976\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)              │          \u001b[38;5;34m66,625\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,246,976</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">66,625</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,330,241\u001b[0m (20.33 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,330,241</span> (20.33 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,330,241\u001b[0m (20.33 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,330,241</span> (20.33 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating loss function"
      ],
      "metadata": {
        "id": "b-OINJSzLBXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch,target_example_batch in data.take(1):\n",
        "  example_batch_predictions=model(input_example_batch) #ask our model for aprediction on our first batch of training data\n",
        "  print(example_batch_predictions.shape,\"# (batch_size, sequence_length,vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z82pagthHUxu",
        "outputId": "744464a8-9767-48ff-db6b-9b8c70e03997"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 65) # (batch_size, sequence_length,vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(example_batch_predictions))\n",
        "print(example_batch_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WgEHMA5vMjh2",
        "outputId": "49696fbb-e948-4aa9-c6de-c5df5f4cd536"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n",
            "tf.Tensor(\n",
            "[[[-4.47535701e-03 -6.38556620e-03  1.86693540e-03 ... -4.45628678e-03\n",
            "    1.55942258e-03  3.75115289e-03]\n",
            "  [-1.46600278e-03  9.61179467e-05  1.53545104e-03 ... -9.19833966e-03\n",
            "   -6.38451194e-04  3.54639557e-03]\n",
            "  [-4.25120303e-03  7.60611147e-04  3.15016764e-03 ... -8.86621047e-03\n",
            "   -6.10497082e-04  1.53507444e-03]\n",
            "  ...\n",
            "  [ 9.34165716e-03  7.75493030e-03  7.63940904e-03 ...  5.20302774e-03\n",
            "   -8.15550983e-03 -3.30788339e-03]\n",
            "  [ 5.30312443e-03  8.16131476e-03  9.17068869e-03 ...  1.13695720e-02\n",
            "   -5.94360335e-03 -5.01992356e-04]\n",
            "  [ 4.59625665e-03  7.67902751e-03  8.98114964e-03 ...  1.09219104e-02\n",
            "   -7.06301117e-03 -3.59634473e-03]]\n",
            "\n",
            " [[ 4.09850836e-05 -5.51115302e-03 -8.93503334e-03 ...  1.34692586e-03\n",
            "    5.93029708e-03  4.96851513e-04]\n",
            "  [ 3.42853367e-03 -2.82472954e-03 -8.28641374e-03 ... -3.39888153e-04\n",
            "    1.15102557e-02 -2.81255948e-03]\n",
            "  [ 4.77665849e-03 -4.45961545e-04 -1.19157284e-02 ...  8.60534128e-05\n",
            "    7.32537918e-03 -6.11716742e-03]\n",
            "  ...\n",
            "  [ 3.15722078e-03  3.30166006e-03  1.09058910e-03 ...  1.40184769e-04\n",
            "    1.49875309e-03 -8.59053899e-03]\n",
            "  [ 7.34253693e-03  6.98930630e-03  6.17068401e-03 ...  7.21635181e-04\n",
            "    3.40706320e-03 -7.62056699e-03]\n",
            "  [ 1.08396923e-02  1.04354825e-02  9.58255306e-03 ...  1.37489883e-03\n",
            "    5.55318315e-03 -6.97728386e-03]]\n",
            "\n",
            " [[ 2.06235494e-03  3.04337381e-03  5.17175125e-04 ... -6.83514820e-03\n",
            "   -2.69978819e-03 -3.79170640e-03]\n",
            "  [ 8.55970313e-04  6.32305397e-03  3.38455988e-03 ... -8.41070525e-03\n",
            "   -7.30830524e-03 -3.75649938e-03]\n",
            "  [-1.04664569e-03  6.18475024e-03  1.12933693e-02 ... -3.34469229e-03\n",
            "   -6.77144679e-04  2.42892816e-03]\n",
            "  ...\n",
            "  [ 2.25157104e-03 -3.40448663e-04  2.19661059e-04 ...  7.36598065e-03\n",
            "    3.91829293e-03 -3.60918255e-03]\n",
            "  [ 5.98158862e-04 -3.82182794e-03  1.84626866e-03 ...  6.67565688e-03\n",
            "    6.84910500e-03 -4.81849257e-03]\n",
            "  [ 5.95940510e-04 -1.36357115e-03 -3.31278867e-03 ...  5.92942769e-03\n",
            "    5.68130100e-03 -8.88759550e-03]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 1.19006902e-03  1.47468119e-03 -4.85208258e-03 ...  5.91410324e-04\n",
            "   -3.86259635e-04 -4.38523199e-03]\n",
            "  [ 8.25589057e-04 -3.50423087e-03 -1.71685906e-03 ...  1.36021338e-03\n",
            "    1.73935120e-03 -4.52839863e-03]\n",
            "  [-3.99886630e-04 -1.96132532e-04  1.46459369e-03 ... -1.51661073e-03\n",
            "   -4.62943083e-03 -4.94687213e-03]\n",
            "  ...\n",
            "  [ 5.86363394e-03  3.05963960e-03 -7.41142081e-03 ... -3.11600696e-03\n",
            "    4.41321731e-03 -1.22411745e-02]\n",
            "  [ 3.86065478e-03  4.80906619e-03 -1.87696260e-03 ...  1.45417196e-03\n",
            "    8.43350496e-03 -4.35859943e-03]\n",
            "  [ 9.37945116e-03  7.68792490e-03  2.83624860e-03 ...  1.30410108e-03\n",
            "    7.33065978e-03 -5.16885798e-03]]\n",
            "\n",
            " [[ 1.19006902e-03  1.47468119e-03 -4.85208258e-03 ...  5.91410324e-04\n",
            "   -3.86259635e-04 -4.38523199e-03]\n",
            "  [-6.50822592e-04  3.52092134e-03  8.34402454e-04 ...  4.15643537e-03\n",
            "    5.46774175e-03  2.26650597e-03]\n",
            "  [ 9.66782623e-04  4.00990481e-03  1.44338177e-03 ...  3.82056809e-03\n",
            "    6.25396147e-03  6.89753471e-03]\n",
            "  ...\n",
            "  [ 3.03852884e-03 -8.70251388e-04 -7.34063890e-03 ...  1.85027230e-03\n",
            "    1.52691989e-03 -1.19274633e-03]\n",
            "  [ 4.08537406e-03  2.38797371e-03 -4.97758808e-03 ...  5.94867906e-03\n",
            "   -3.36298393e-03  2.46395328e-04]\n",
            "  [ 1.92058051e-03  4.68567852e-03 -3.22305504e-03 ...  3.77712119e-03\n",
            "   -6.82789134e-03  4.17854125e-03]]\n",
            "\n",
            " [[-3.08370753e-03 -2.58442690e-03 -2.75375135e-03 ...  8.86148401e-03\n",
            "    3.38278199e-03  1.11239520e-03]\n",
            "  [-1.45290606e-03 -2.66927830e-03 -2.44968280e-04 ...  5.14750089e-03\n",
            "   -1.00685563e-03 -5.31290250e-04]\n",
            "  [-6.99778728e-04 -3.12591874e-04 -4.68608923e-03 ...  4.23062220e-03\n",
            "   -1.20848243e-03 -4.90502687e-03]\n",
            "  ...\n",
            "  [ 4.39655036e-03 -1.82752346e-03 -4.78343433e-03 ...  1.19101433e-02\n",
            "    3.83541617e-03  7.80920673e-04]\n",
            "  [ 3.40309972e-03  8.68717500e-04 -8.66352639e-04 ...  8.70271120e-03\n",
            "    7.44203804e-04 -2.28913943e-03]\n",
            "  [-3.37350881e-03  8.20836925e-04 -3.15697119e-03 ...  3.18857608e-03\n",
            "    3.54956486e-03 -3.23955086e-03]]], shape=(64, 100, 65), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#examine one prediction\n",
        "pred=example_batch_predictions[0]\n",
        "print(len(pred))\n",
        "print(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppr40LClMxtG",
        "outputId": "54fdbe6c-8d4a-4777-cdbb-cf23be197ef7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "tf.Tensor(\n",
            "[[-4.4753570e-03 -6.3855662e-03  1.8669354e-03 ... -4.4562868e-03\n",
            "   1.5594226e-03  3.7511529e-03]\n",
            " [-1.4660028e-03  9.6117947e-05  1.5354510e-03 ... -9.1983397e-03\n",
            "  -6.3845119e-04  3.5463956e-03]\n",
            " [-4.2512030e-03  7.6061115e-04  3.1501676e-03 ... -8.8662105e-03\n",
            "  -6.1049708e-04  1.5350744e-03]\n",
            " ...\n",
            " [ 9.3416572e-03  7.7549303e-03  7.6394090e-03 ...  5.2030277e-03\n",
            "  -8.1555098e-03 -3.3078834e-03]\n",
            " [ 5.3031244e-03  8.1613148e-03  9.1706887e-03 ...  1.1369572e-02\n",
            "  -5.9436033e-03 -5.0199236e-04]\n",
            " [ 4.5962567e-03  7.6790275e-03  8.9811496e-03 ...  1.0921910e-02\n",
            "  -7.0630112e-03 -3.5963447e-03]], shape=(100, 65), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction at the first timestamp\n",
        "time_pred=pred[0]\n",
        "print(len(time_pred))\n",
        "print(time_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tgTn1_zM_Aa",
        "outputId": "ca41988d-ff55-4f89-9fc1-6d02164f9729"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65\n",
            "tf.Tensor(\n",
            "[-4.4753570e-03 -6.3855662e-03  1.8669354e-03 -8.9455361e-04\n",
            "  4.7953320e-03  6.0206209e-03  4.0617273e-03 -2.3540817e-03\n",
            " -1.8198616e-03  2.5351212e-04 -1.8807746e-03  8.2353008e-04\n",
            "  7.5220771e-04 -4.3601114e-03 -3.8000106e-04  3.1382022e-03\n",
            " -3.6413099e-03 -5.5203843e-03 -3.5231023e-03 -1.9056926e-04\n",
            "  4.5033335e-03  6.3881319e-04 -1.2329571e-03 -4.5609223e-03\n",
            " -4.7779168e-04 -5.4198229e-03 -6.4648599e-03  1.1239626e-03\n",
            "  9.0522564e-04  2.2085740e-03 -2.5423762e-04 -2.4571291e-03\n",
            " -4.2497762e-03  1.3020060e-03 -1.3874591e-03 -2.1951615e-03\n",
            " -3.9154198e-03  1.5499425e-03 -3.5458670e-03  2.0686151e-03\n",
            " -2.2978901e-03 -3.2178010e-03 -4.8027290e-03 -7.6828431e-04\n",
            " -4.9587125e-03 -2.0162040e-06  4.9274536e-03 -7.6648891e-03\n",
            " -1.4188200e-03  1.6657751e-03 -3.9306539e-03 -1.7531289e-04\n",
            " -3.1853386e-03 -8.8487455e-04 -3.4061600e-03  4.6583735e-03\n",
            "  2.4065222e-03  3.5473227e-03 -5.1855766e-03 -2.5587871e-03\n",
            "  1.3284090e-03 -7.3565857e-04 -4.4562868e-03  1.5594226e-03\n",
            "  3.7511529e-03], shape=(65,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if we want to determine the predicted character we need to sample the output distribution ie picking a value based on probability"
      ],
      "metadata": {
        "id": "0B4zq_OvS3sG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_indices=tf.random.categorical(pred,num_samples=1)\n",
        "#now we can reshape that array and convert integers to number to see character\n",
        "sampled_indices=np.reshape(sample_indices,(1,-1))[0]\n",
        "predicted_char=int_to_text(sampled_indices)\n",
        "predicted_char"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7YDu3ZQnShmx",
        "outputId": "f63bf35d-8848-4f36-9349-6c6a41461b98"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"tc,aOxvzjyAK\\nC.a!MkL:rK&M&k:$wgGN'LvRWX.rXXKS-Vvw$q!YeYfPxs$e$vrYJqzntCZ;CTBpAzN?&p'pJNmvB'cdpPN'iev\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(labels,logits):\n",
        "  return keras.losses.sparse_categorical_crossentropy(labels,logits,from_logits=True)"
      ],
      "metadata": {
        "id": "J2eSRtNtUFsX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compiling the model\n",
        "model.compile(optimizer='adam',loss=loss)"
      ],
      "metadata": {
        "id": "kEnXwYb4UbEs"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating checkpoint\n",
        "#dir where checkpoint will be saved\n",
        "checkpoint_dir='./training_checkpoint'\n",
        "#check point name\n",
        "checkpoint_prefix=os.path.join(checkpoint_dir,\"ckpt_{epoch}.weights.h5\")\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True\n",
        ")"
      ],
      "metadata": {
        "id": "mKWHp6myUpsy"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "training"
      ],
      "metadata": {
        "id": "tl4iMdpLWyGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(data,epochs=40,callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0uSbTT8rWvAp",
        "outputId": "de883145-198b-40b7-dbdc-08a07df63f28"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 64ms/step - loss: 2.8635\n",
            "Epoch 2/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 65ms/step - loss: 1.8580\n",
            "Epoch 3/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 66ms/step - loss: 1.6059\n",
            "Epoch 4/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 66ms/step - loss: 1.4844\n",
            "Epoch 5/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 67ms/step - loss: 1.4058\n",
            "Epoch 6/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 69ms/step - loss: 1.3561\n",
            "Epoch 7/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 69ms/step - loss: 1.3154\n",
            "Epoch 8/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 69ms/step - loss: 1.2787\n",
            "Epoch 9/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 70ms/step - loss: 1.2423\n",
            "Epoch 10/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 71ms/step - loss: 1.2111\n",
            "Epoch 11/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 71ms/step - loss: 1.1787\n",
            "Epoch 12/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 71ms/step - loss: 1.1510\n",
            "Epoch 13/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 72ms/step - loss: 1.1173\n",
            "Epoch 14/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 71ms/step - loss: 1.0844\n",
            "Epoch 15/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - loss: 1.0495\n",
            "Epoch 16/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 71ms/step - loss: 1.0155\n",
            "Epoch 17/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 70ms/step - loss: 0.9776\n",
            "Epoch 18/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 71ms/step - loss: 0.9432\n",
            "Epoch 19/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - loss: 0.9069\n",
            "Epoch 20/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - loss: 0.8693\n",
            "Epoch 21/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 70ms/step - loss: 0.8311\n",
            "Epoch 22/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 70ms/step - loss: 0.8004\n",
            "Epoch 23/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - loss: 0.7696\n",
            "Epoch 24/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 71ms/step - loss: 0.7356\n",
            "Epoch 25/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 71ms/step - loss: 0.7070\n",
            "Epoch 26/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 71ms/step - loss: 0.6789\n",
            "Epoch 27/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 71ms/step - loss: 0.6566\n",
            "Epoch 28/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 71ms/step - loss: 0.6295\n",
            "Epoch 29/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 71ms/step - loss: 0.6083\n",
            "Epoch 30/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 71ms/step - loss: 0.5919\n",
            "Epoch 31/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 71ms/step - loss: 0.5711\n",
            "Epoch 32/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 71ms/step - loss: 0.5559\n",
            "Epoch 33/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 71ms/step - loss: 0.5442\n",
            "Epoch 34/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 71ms/step - loss: 0.5278\n",
            "Epoch 35/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - loss: 0.5150\n",
            "Epoch 36/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 71ms/step - loss: 0.5037\n",
            "Epoch 37/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - loss: 0.4944\n",
            "Epoch 38/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 71ms/step - loss: 0.4836\n",
            "Epoch 39/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 71ms/step - loss: 0.4755\n",
            "Epoch 40/40\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 71ms/step - loss: 0.4683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model=build_model(VOCAB_SIZE,EMBEDDING_DIM,RNN_UNITS,batch_size=1)\n",
        "\n",
        "model.build(input_shape=(1,None))\n",
        "model.load_weights('./training_checkpoint/ckpt_40.weights.h5')\n",
        "model.build(input_shape=(1,None))"
      ],
      "metadata": {
        "id": "YN5psW24aHdi"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "print(latest_checkpoint)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ4Pe4HLgrnv",
        "outputId": "ea9a3702-7898-4118-ba82-e4757415920b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.build(tf.TensorShape([1,None]))\n",
        "model.load_weights('./training_checkpoint/ckpt_4.weights.h5')\n",
        "model.build(tf.TensorShape([1,None]))"
      ],
      "metadata": {
        "id": "30e33CDhaZu2"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading specific checkpoint\n",
        "checkpoint_num=40\n",
        "model.load_weights(\"./training_checkpoint/ckpt_\"+str(checkpoint_num)+\".weights.h5\")\n",
        "model.build(tf.TensorShape([1,None]))"
      ],
      "metadata": {
        "id": "jSKocBS2dmHA"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generating text\n",
        "def generate_text(model,start_string):\n",
        "\n",
        "  #num of character to generate\n",
        "  num_generate=400\n",
        "  input_eval=[char2indx[s] for s in start_string]\n",
        "  input_eval=tf.expand_dims(input_eval,0)\n",
        "\n",
        "  text_generated=[]\n",
        "  #low temp= more predictable text\n",
        "  #high temp=more surprising text\n",
        "  temperature=1.2\n",
        "  #here batch_size =1\n",
        "  #model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "    predictions=model(input_eval)\n",
        "    predictions=predictions[:,-1,:]\n",
        "    predictions=predictions/temperature\n",
        "    predicted_id=tf.random.categorical(predictions,num_samples=1)[-1,0].numpy()\n",
        "\n",
        "    input_eval=tf.expand_dims([predicted_id],0)\n",
        "    text_generated.append(indx2char[predicted_id])\n",
        "  return(start_string+\"\".join(text_generated))"
      ],
      "metadata": {
        "id": "AQTOy52ufFF9"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp=input(\"type a starting string:\")\n",
        "print(generate_text(model,inp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wk2j-qNFBV_Z",
        "outputId": "5872dcd0-a1af-4165-93aa-aa967ef1ea7f"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type a starting string:ISABELLA\n",
            "ISABELLA:\n",
            "Grands of thing.\n",
            "\n",
            "PERDITA:\n",
            "O slave!\n",
            "Why that's some coy.\n",
            "Now, then indeed the better, the mouty testamony\n",
            "That crew caps that our chances with my wounds, and from the father,\n",
            "Stand you my five reasons well encounter'd,\n",
            "Which should bequice me to question\n",
            "Are you most Ducy find straight long hath touch'd upon't:\n",
            "Therefore thy mind come near my soul's curse,\n",
            "Lest Isabellare,\n",
            "No more words it gains\n"
          ]
        }
      ]
    }
  ]
}